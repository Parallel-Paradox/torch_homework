{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 13680\n",
      "(tensor([[  0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  12., 233., 255.],\n",
      "        [  0.,   0.,  12., 233., 255.],\n",
      "        [  0.,   0.,   7., 201., 255.]], dtype=torch.float64), 1)\n"
     ]
    }
   ],
   "source": [
    "# Custom torch Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class EdgeDataset(Dataset):\n",
    "    def get_negative_pair(self, image_id, label, center):\n",
    "        \"\"\"give the center coordinate of positive, scan and get a negative surround\"\"\"\n",
    "        negative = []\n",
    "        for row in range(center[0]-2, center[0]+3):\n",
    "            for col in range(center[1]-2, center[1]+3):\n",
    "                if col < 0 or col > len(label[row]):\n",
    "                    continue\n",
    "                if 0 <= row < len(label) and 0 <= col < len(label[row]) and label[row][col] == 0:\n",
    "                    negative.append((image_id, row, col, 0))\n",
    "        return negative[random.randint(0, len(negative)-1)]\n",
    "\n",
    "    def set_attention(self, image_id):\n",
    "        \"\"\"get the positive list with its negative pair, ignore the other\"\"\"\n",
    "        label = self.label_list[image_id]\n",
    "        attention = []    # positive and negative coordinate that is going to be saved.\n",
    "        for row in range(0, len(label)):\n",
    "            for col in range(0, len(label[row])):\n",
    "                if label[row][col] != 0:   # positive coordinate\n",
    "                    attention.append((image_id, row, col, 1))\n",
    "                    attention.append(self.get_negative_pair(image_id, label, (row, col)))   # negative pair\n",
    "        return attention\n",
    "\n",
    "    def __init__(self, image_path, label_path):\n",
    "        \"\"\"Edge detect dataset.\n",
    "            Add several random pure color block to make pos:neg equals to 1:2. \\n\n",
    "            No extra pure plock is stored, but return pure color when index is in a specific range. \\n\n",
    "\n",
    "        :param image_path: source image path\n",
    "        :param label_path: label image path\n",
    "        \"\"\"\n",
    "        self.point_list = []\n",
    "\n",
    "        file_name = os.listdir(image_path)\n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "        for name in file_name:\n",
    "            image = Image.open(image_path + name)\n",
    "            label = Image.open(label_path + name)\n",
    "            self.image_list.append(np.array(image))\n",
    "            self.label_list.append(np.array(label))\n",
    "\n",
    "        for img_id in range(0, len(self.image_list)):\n",
    "            self.point_list.extend(self.set_attention(img_id))\n",
    "\n",
    "        self.size = len(self.point_list)    # length of meaningful point\n",
    "        self.length = int(self.size * 1.5)  # length of index access range\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    @staticmethod\n",
    "    def from_center_5x5(arr, center_row, center_col):\n",
    "        \"\"\"sample a 5x5 sub array from data by center coordinate\"\"\"\n",
    "        center_5x5 = np.zeros((5, 5))\n",
    "        for row in range(center_row - 2, center_row + 3):\n",
    "            for col in range(center_col - 2, center_col + 3):\n",
    "                if 0 <= row < len(arr) and 0 <= col < len(arr[row]):\n",
    "                    center_5x5[row - center_row + 2][col - center_col + 2] = arr[row][col]\n",
    "        return center_5x5\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if type(index) == int:\n",
    "            if 0 <= index < self.size:\n",
    "                point = self.point_list[index]\n",
    "                image_slice = self.from_center_5x5(self.image_list[point[0]], point[1], point[2])\n",
    "                image_slice = torch.tensor(image_slice)\n",
    "                return image_slice, point[3]\n",
    "            elif self.size <= index < self.length:\n",
    "                image_slice = torch.full((5, 5), random.randint(0, 255))\n",
    "                return image_slice, 0\n",
    "            else:\n",
    "                raise IndexError(\"Index out of range!\")\n",
    "        else:\n",
    "            raise TypeError(\"Type of index has to be int!\")\n",
    "\n",
    "\n",
    "dataset = EdgeDataset(\"./source_images(examples)/data/\", \"./source_images(examples)/edge/\")\n",
    "print(\"dataset size:\", len(dataset))\n",
    "print(dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000 * 4] loss 0.643\n",
      "[1,  2000 * 4] loss 0.604\n",
      "[1,  3000 * 4] loss 0.269\n",
      "[2,  1000 * 4] loss 0.073\n",
      "[2,  2000 * 4] loss 0.054\n",
      "[2,  3000 * 4] loss 0.055\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(25, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 4)\n",
    "        self.fc4 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1).to(torch.float32)\n",
    "        x = torch.divide(x, 255.0)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = f.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img_slice, img_label = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(img_slice)\n",
    "        loss = criterion(outputs, img_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d} * 4] loss {running_loss / 1000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAABkklEQVR4nO3Y0XKDIBAFUDrT//9l+2CTaGSRGBScOeelMy2we4PVYEoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEAbP70b+NwU/L4uyq0Cz1GDlqfC3xZuErgYdT1uZ9DwgWujLieURg8c+OOoi4nxrCEDH466WCCaPVjgr6O+FgoWGSXw/7OmYTtB5P6Bm21qZuXMqh0Dt9/UbYXt4l0Cn7epm0qbItcGPn9TNxXfa11U+/qkz8pvNX9PLvf/s/+98eGkwOMFfWgb+HlyGy/oQ4vArwPquDmfjra4PIVfFnN19K+qun0SZ6dlztLvrxnOCxm90FhXLY2aBwYP+1zj88cy7Y5rpP1nWfpikw18wTX6+dXZSLzDp1jk7HSDC/6HG3cz0H0830CzxOM9mMN3nl92OOxXraihLxL3OyjUiNs6EHnsqLNCc/svtdeDy6uNothiXeTbZE0p7fa5E/leWVNKFc1OwaAbZk0pHbtk75o1pVTd9mUnCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOjjD6waQi5nMSStAAAAAElFTkSuQmCC\n"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edge_detect(image_path, file_name):\n",
    "    image = np.array(Image.open(image_path + file_name).convert('L'))\n",
    "    height = len(image)\n",
    "    width = len(image[0])\n",
    "    edge = np.zeros((height, width))\n",
    "    for row in range(0, len(image)):\n",
    "        for col in range(0, len(image[row])):\n",
    "            input_slice = EdgeDataset.from_center_5x5(image, row, col)\n",
    "            input_slice = input_slice[np.newaxis, :, :]\n",
    "            pix_output = net(torch.tensor(input_slice))\n",
    "            if pix_output[0][0] > pix_output[0][1]:\n",
    "                edge[row][col] = 0\n",
    "            else:\n",
    "                edge[row][col] = 255\n",
    "    edge = np.uint8(edge)\n",
    "    return Image.fromarray(edge)\n",
    "\n",
    "edge_detect(\"./source_images(examples)/data/\", \"4-0-0-0-1-0.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAAT0lEQVR4nO3BMQEAAADCoPVPbQZ/oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgPh8AABp0pKQgAAAABJRU5ErkJggg==\n"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-0.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAAiklEQVR4nO3cQQqAQAgFULv/oadNm4iBGrSE3tsK8v8BNAIAAAAAAAAAAAAAAAAAAAAAAE622WBkrXq+KMm02sVnEQEAAAAAAAAAAAAAAP7q/unHmuyDkeq8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAKzL/k0dEU0fVI/CXL0KVzY9NCn8QlMAAMi1A7PaCASVsf7IAAAAAElFTkSuQmCC\n"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-1.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAACpklEQVR4nO3d0W7CMAyFYZj2/q+cXQw0Bik0re2c2P93MWloIjlxGpIK2OUCAAAAAAAA4L82uwMAAADIhQ1mepQYAAAAAVrgvvMa19SGptCJQJHVFUDczIrFrXZHoFh5a8Vt5aYzADsv+/Z2bd3HF/S7ND4l6QR+/OuF7S3Z8kGfPOf5mtKLiQicHYGzI3B2BM6OwNkROLtygb/7Dx87JPaOoDOPm9fLa59ebwD0H15Rmls3AAAAAAAAcLPE20PK3aZ1DqxXdCqcHYGzI3B2BM6uXGBn7LSmKxcY2bm/5yNm2eKtK8DSBhYKw9dhvV1VT7mNB4Gx2xrXMLCAkYup3KJF4Ow2PtVyQIv5TMvZk69d4C4O5khFcbNZbpXOEHhoIpkFVpy+Pa4V5kXpvN5EmjOlOyRneYZFa4hVYMlqeooKXG5glWkWg0XrGM1qJjU22H5TWrToNoHDwp1vyCbwQqcEvyktOggmgU8fYTLwCSw8jMJdg4W4Ag+2xF4a6jSmtNMlbPC0TGlpshUW3nUwpVczOplcKiw8o9enUGHpArNorUZgOvl1QSBcLIvA9tdwuTI46ozl/OEN7sH8wMGGA1tfw+VGPNrsClPg5CiwKZPhNL2GKbAtk40W5+G1UOGP7AKzYgFjuGYKOlB0XpayIzAARDmy9yq3aJULjIUcOj5JT+nmcCI88eVD3a9XsnH7Z9geDcz9OFW/gjv75DjgmrgD4klgdEO7IJA3FHlzs82rP3oKPYzsg0Bejx3ndmOBbYV04cPozc8bWt7peVts3Mmf629+cTeed2Z9zcKucMRqF8N+bj2RyGHzdicgrKnNXz2buj/qc81u3uL5P6yhBW+dDph5d0/rL2VM3ns9XRt7++T3nN55Q5Lu0h5+1tBqxQUAALD0A9tLoTKkN8R3AAAAAElFTkSuQmCC\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-2.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAEb0lEQVR4nO2d2ZYbIQxEcc78/y+TB9sTp43obtBSiLoPORk7g7oosWOnFEIIIYQQkoYaGv2Pb7gaq9ad+vHnBtSvvwTw4xaplodbLASq+ENK9uysei+koqUuseLtslnQm7caJGVBih2mlnm9FACz2AEoZc6rpf+AqghVkJLax+G8XgogWewDjrLITqsgVYQ2MEkd7HBiUCz2czhvcxVAsdgPLoxPXl8fCMUclixBsJgOmwJgMR22pWll9dyr9zsulailZD5IPXrp6m4p0Q7X1OY++TQ04pwt0OEd7C3l12L3xvsiyuGdrrjUOHtLkMM72UsI0eWr96jSG8vxUnIQ8t1LP/9BgttVLyGHV6VhaX2DBbbb8aDg7FBwdig4OxScHQrODgVnZzvB7eXh4GK4saYMXVa31rjSjkeG9fBTirMSuI0T1TYMp67Bdp0WBWeHgrOznWBr4EYqTYfhxLXYLqUpODsUnB1jwXgdt7XDcBsJTOnsUHB2KDg7FJwdCs4OBWeHgrNDwdnZTrAmePs5RHXPqbbK8nI9Yu8sMqOvx2anNU6gwzdCb+cwBWeHgrNDweQyceNwTOQ15h37pTQFZ8f2u3gM2vXswtdWMNyVFuuUBtzlMhVsoXe2TD3Blz4GZgLOvMPpSW6FWW1Ymq7D1QRPQ8GKAA5KeoKbxw6A8w6mdHooeBC0j/+LKAluikPss5ZL6elMWkzwfCYpCYbM3iY6gptLJcxKWCyl56HgEUCzt4mZw6iVwJQeANXMJlYO+02kb1a3WUrbuD5fqoJgx4xWyJvtOi0jjJqwwm7/vMOY63wRpvRd2v/PnWMw95TejHb9Ojp8N5SJw8hzzUnByNLaLNWG46vXtwWr3DJYymENpgS3Uwx76mXhcHhL6zEjOL4PgcAwoxXmHTMOY7dVfQS9ltUQ7PBmBBisEm/Y4YAeWqUyRwVLBsOPVIOC8YX5YNuCVW4ojzkMMwQH38g2Dq8xDI85LDRgGN97jAgWhSXtyYISOiyldxuRxDoNacEODkv+2uvViXBXsBw1Z6ZHJnSrz7JOabHDihqCjdNKlhUk2H9q5xNYjOG/WPGI2wkyEFjlJp5CGedBlJrrdcGdiClHJMCE9t70tw96GsQuNqhe15No65gXyKrXfT6LqtfzRqdtxKuYhO+Z6LAGVg9/9l08tTOrMN7sqcViSnMiuKfJTO/LuYgPERjrlXLyWskGFd5rJCrtd6oQ/R7EXO/UsKaut/swWtGABHfL0ws2XNKieoeL0p7jeekdRvcZ+qV5xkJ4BgB/dfP5pDD90eD+b8w8w3Fq2Zs7l4JwWFrnJp2H3z0p7aw67JmU2yzSe71/o9DuavEaze+2ES+tmPh7tZXoLBcby8OHoCwyn2spSrncLqSlLUzvM4u1gosHvsc3DPV2clrP2TfSjsfjINDdX6ttj17lfrxnOvweCn93xO5bPP8UG9v7Fmyr9ErhryexTuffsTV6VvN6lNDjI2+qxuQGigs3AOITjRBCCCE5+AtcOlRcoQaoPQAAAABJRU5ErkJggg==\n"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-3.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}