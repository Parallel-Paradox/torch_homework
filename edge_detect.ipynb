{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 13680\n",
      "(tensor([[  0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  12., 233., 255.],\n",
      "        [  0.,   0.,  12., 233., 255.],\n",
      "        [  0.,   0.,   7., 201., 255.]], dtype=torch.float64), 1)\n"
     ]
    }
   ],
   "source": [
    "# Custom torch Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class EdgeDataset(Dataset):\n",
    "    def get_negative_pair(self, image_id, label, center):\n",
    "        \"\"\"give the center coordinate of positive, scan and get a negative surround\"\"\"\n",
    "        negative = []\n",
    "        for row in range(center[0]-2, center[0]+3):\n",
    "            for col in range(center[1]-2, center[1]+3):\n",
    "                if col < 0 or col > len(label[row]):\n",
    "                    continue\n",
    "                if 0 <= row < len(label) and 0 <= col < len(label[row]) and label[row][col] == 0:\n",
    "                    negative.append((image_id, row, col, 0))\n",
    "        return negative[random.randint(0, len(negative)-1)]\n",
    "\n",
    "    def set_attention(self, image_id):\n",
    "        \"\"\"get the positive list with its negative pair, ignore the other\"\"\"\n",
    "        label = self.label_list[image_id]\n",
    "        attention = []    # positive and negative coordinate that is going to be saved.\n",
    "        for row in range(0, len(label)):\n",
    "            for col in range(0, len(label[row])):\n",
    "                if label[row][col] != 0:   # positive coordinate\n",
    "                    attention.append((image_id, row, col, 1))\n",
    "                    attention.append(self.get_negative_pair(image_id, label, (row, col)))   # negative pair\n",
    "        return attention\n",
    "\n",
    "    def __init__(self, image_path, label_path):\n",
    "        \"\"\"Edge detect dataset.\n",
    "            Add several random pure color block to make pos:neg equals to 1:2. \\n\n",
    "            No extra pure plock is stored, but return pure color when index is in a specific range. \\n\n",
    "\n",
    "        :param image_path: source image path\n",
    "        :param label_path: label image path\n",
    "        \"\"\"\n",
    "        self.point_list = []\n",
    "\n",
    "        file_name = os.listdir(image_path)\n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "        for name in file_name:\n",
    "            image = Image.open(image_path + name)\n",
    "            label = Image.open(label_path + name)\n",
    "            self.image_list.append(np.array(image))\n",
    "            self.label_list.append(np.array(label))\n",
    "\n",
    "        for img_id in range(0, len(self.image_list)):\n",
    "            self.point_list.extend(self.set_attention(img_id))\n",
    "\n",
    "        self.size = len(self.point_list)    # length of meaningful point\n",
    "        self.length = int(self.size * 1.5)  # length of index access range\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    @staticmethod\n",
    "    def from_center_5x5(arr, center_row, center_col):\n",
    "        \"\"\"sample a 5x5 sub array from data by center coordinate\"\"\"\n",
    "        center_5x5 = np.zeros((5, 5))\n",
    "        for row in range(center_row - 2, center_row + 3):\n",
    "            for col in range(center_col - 2, center_col + 3):\n",
    "                if 0 <= row < len(arr) and 0 <= col < len(arr[row]):\n",
    "                    center_5x5[row - center_row + 2][col - center_col + 2] = arr[row][col]\n",
    "        return center_5x5\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if type(index) == int:\n",
    "            if 0 <= index < self.size:\n",
    "                point = self.point_list[index]\n",
    "                image_slice = self.from_center_5x5(self.image_list[point[0]], point[1], point[2])\n",
    "                image_slice = torch.tensor(image_slice)\n",
    "                return image_slice, point[3]\n",
    "            elif self.size <= index < self.length:\n",
    "                image_slice = torch.full((5, 5), random.randint(0, 255))\n",
    "                return image_slice, 0\n",
    "            else:\n",
    "                raise IndexError(\"Index out of range!\")\n",
    "        else:\n",
    "            raise TypeError(\"Type of index has to be int!\")\n",
    "\n",
    "\n",
    "dataset = EdgeDataset(\"./source_images(examples)/data/\", \"./source_images(examples)/edge/\")\n",
    "print(\"dataset size:\", len(dataset))\n",
    "print(dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000 * 4] loss 0.649\n",
      "[1,  2000 * 4] loss 0.635\n",
      "[1,  3000 * 4] loss 0.632\n",
      "[2,  1000 * 4] loss 0.519\n",
      "[2,  2000 * 4] loss 0.202\n",
      "[2,  3000 * 4] loss 0.131\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(25, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 4)\n",
    "        self.fc4 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1).to(torch.float32)\n",
    "        x = torch.divide(x, 255.0)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = f.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img_slice, img_label = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(img_slice)\n",
    "        loss = criterion(outputs, img_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d} * 4] loss {running_loss / 1000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAABhklEQVR4nO3Z0W6DIBgGUJrs/V/ZXXSuRf2pWhRIzrlcFb4vpBVcSgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQB2P1gGOm4K/76syVOG56mboKfwkM0jhv6qf0k6fr+m+8M6q2fWlizsufLTq+43xTV0WPl31NUB4b2eFv676GigYo5fCxR/gkyNujtW+cP2qRQ0L39y0yWxP/1ulFpPfO2ebRc3cM3XTNc1dnKB902kx80VB2hedLZ9OP5VHnzUvGqkQ7P182l3P1fbj7Apnp/C7ah6fdP2yID5L5x+t7ryqZPQ+YzFp8bKUHuETcCv3lB7rEa9bxfozbSxYcfTC4aqaJl+JcK7ls6uaDn7fgu9w5TQdPa62A1Rr3M8GZBYE+bpxB8eEbVGg4ouwom6rPsWxTixytTdSFyqEO7LII1R9KkbcVXmcrimljznLlQfrmlLaETb418WIXVNKuxKvdqalrWr3dsbON/iDdgUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDYL/DvQCeGCNRiAAAAAElFTkSuQmCC\n"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edge_detect(image_path, file_name):\n",
    "    image = np.array(Image.open(image_path + file_name).convert('L'))\n",
    "    height = len(image)\n",
    "    width = len(image[0])\n",
    "    edge = np.zeros((height, width))\n",
    "    for row in range(0, len(image)):\n",
    "        for col in range(0, len(image[row])):\n",
    "            input_slice = EdgeDataset.from_center_5x5(image, row, col)\n",
    "            input_slice = input_slice[np.newaxis, :, :]\n",
    "            pix_output = net(torch.tensor(input_slice))\n",
    "            if pix_output[0][0] > pix_output[0][1]:\n",
    "                edge[row][col] = 0\n",
    "            else:\n",
    "                edge[row][col] = 255\n",
    "    edge = np.uint8(edge)\n",
    "    return Image.fromarray(edge)\n",
    "\n",
    "edge_detect(\"./source_images(examples)/data/\", \"4-0-0-0-1-0.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAAT0lEQVR4nO3BMQEAAADCoPVPbQZ/oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgPh8AABp0pKQgAAAABJRU5ErkJggg==\n"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-0.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAB2UlEQVR4nO3cW07EMAwF0IDY/5bLB+IDNDNSO0ns2ucsoPgmTtIHMAYAAAAAAAAAAAAAz3xEFzDGOHKUAQCUdEQXAAAx/h+BnyFVBBK4OoGrE7g6gasTuDqBq2sX+Ml3ymvvFR9cLPQF5aNwT2os8r22UBQAAAAAYI58v0ba7kU8cIZNK5zA1QlcncAAwHtOPJS1O4cFrk5gINyZd6Pt1rDA1X0tvfqCDw/+ZmPYtNgm37fDhi1dIfCpRqoQ+JR2gStI09IZN+l+LS0w+WXZK7LU8Ve7lm4XuIBzS2fdDOdcwv1aWmAu2reEs2xa3STdpJkl6xLut4bbBV5k45alpV9rF3iNnYdwigM/RRGPaekZMnd0uxluF3iFrVuWlt5v75lkhlkt8V3WGPdv6fjh3VzB6R939xkOt7vFzPBm2/cQM7xX/CHBUiZ4ufNDPHPT6jbBEXm7jXFoS3cb7Ji83UY5ULeh7pY3yoVxbve0JHB1AgNhrtzutFvDApPXpSeWdjPcLvCNXXsGN8O3cfElixm+C2/RACgp9QH3fnE3+levx5Rq7xJ4Ttpxj8DHmFhn8sDHGJNrzBt4ftax5orv+9mKF1WWKfDvmbO0phyBl84pr6W+8QIAyOwbywJKZgKtDloAAAAASUVORK5CYII=\n"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-1.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAD+ElEQVR4nO2d2ZKcMAxFRSr//8vkIZ2lGrFYu8Q9j1MzxseSZRvoHiIAAAAAAAB6smd3AAAAwNt511JUzPZHdgcAAAAAAAAAAAAAAAAAvIotuwP0+1Z9WD/yhffYTmQLB+tmC4fr5gon6KaypzxXTBtihDeIlFEOXXi/+Jlz2VdlMwDAkGP12LfMImrITsR4HH6wb/9+uzcfkS/Ds2VpQIR5XvdiGoSnA+HpQHg6EJ4OhKcD4em8TvhwPNyIxKdh5kyZeq7mzrjH8zB/o8D0okGk3Owvd+fEdA6Xs2N4XdGC8HQgPB0I21JvoUKENXR4PoMITwfC04GwgnqLLoN3hMutVEjp6UB4OhCeDoSnA+HpQHg6EJ4OhMFzcMejIu6fPQwJe7kbSe48H1bDlE6cwguXft0cHiL8fBIPEX4OhKcD4Y6sLIgjhFeAcEvetpfOmcMtTsNTUnoB3/OwQ9S109X5BkC9ajIhpZfyyFXYo45p27QT5rK3XkaPSOmlcTUTjlqGtUkzIsIreApXrFmIsJgmRdpMuMnRASltSVTQ166DCMv4/qo9IqpZs9pFWD2I3YQ5lgbBSDjqGzz0jdoIs/0oOYVHpPQSEJbALUpV95qIsBlRNWsxlSyE2W1WVbwiXHUKm8DJxQnHp3SrjPZKaacAGzRrINwqwAbC/KiXHQWflC5co9XC2SVrdWydilbZjFYLswEunNEDDg+LyaQUPpnBdTPaJcKVM1oJrxYqXKRK+2Axkjphdq7WzmiV8IlaZMlaHl2NMF+iawdYJXwSycJrEqmEC5RoWh9ehXDLACuEawR4GblwzwBbbzx8A2wxmFLhM7PqARYL82K+ATZpvdVe+sj6GMiET66z189oW5zXJKb5qAjzlF+DiYy/5aFDQjcvWutYfvawQ4ANSZnBiUWrRcUiyzfi3RPaZFXy/cxDRazel7ZpZpmsYU75d2yUl9IhK5LRmNqkdJcJTEZv4hm0cX+ROoOaNYEpaQ4321LqX2pJ9JWk1utOS1oSJ3BKhJtNYNIK9/PVPhBP9RXNJtUD8QBf8xqh+C4ed9+dbjatkuvLhR19P1G9aV8We7Gwia/urZjQApK6/n66IPorYdHK15V2QfwwLXsBlk4pkXABXzES4Qq+4popEG7tK0vpxr7r63CN+MY1V2D9Ne7DdWMFfHddHw7peTk98s+/6hl1/OsLqWzf2+PTA/jvZzh77SzT18L2rAneLP2GrMnlTxph5NJ87WSvGjroeZ73L4oGkfG6/7BAuW43rj6waX7V053W9n8/QtPZS/W+2b/GQb5/NhSuF7ts/GMccnvytjNxFNhOGnI7qBVOR5Y8OA+P8gUAAABAIr8AAgzDGB/1elkAAAAASUVORK5CYII=\n"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-2.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=240x240>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAEmklEQVR4nO2d25YbKQxF8az8/y8zD52VydiCQnchn/2Y7hS1OUJ1tXsMAAAAAADQhJk8/it2uBk/5Buho89s22BmdjmPETnjiLc1dXRDqgzV3Jov080/tXrjn+wdAOA+iq1iAAAAAAAAAAAAAFNw7+M3gRMRfJuWNJsz0Dj9mU/0OwHRwvP/A8a/ApGb8Dc8Vvxrtc6M52x5E5z0Qk/8kD+rOO39paSE8xZvyrCZr6dljPsNvRkA4MRH95irH1zHHIPQ+BT+c15wPT8mb4a/Nr/bkq97TwvC3YFwdyDcHQh3B8LdgXB3vk6YvjwUXg4TF5WpF9bURe7nv83l70p4v/6OxNaENWghLNcw8TCwnO/3NS0IdwfC3YFwdyDcHQh3B8LdgXB3INwdCHfHVPiGd3+8Ey43Byjp7kC4OxDuDoS7A+HuGArXexZMgYRtKXftsPqQhxkxdc6YV2/hmIjn+ThYw92xFK7XoQiaJHw+102Ez4HwjXAO9i2EOUBYzB0XS0j4ThinPD2EGRgKX3Fm6Xx56NDItNPqfD0c9ferznFdwxWPVGbCUXLacW7r0up59RUu2LjthAvKUXgmHNazOHN92xpWYyVcMk0KJCzl7MPJ+TgmXPNUBCUto+JZM81lCesn1kr4lp7lmHDRKrcRLipHYZRwWPWql45j0yq5hG2EqYquWuWXHZb02AhnVi+zlCyE6SFrLmG3kq66hG2Ew8I0mEYD4bJhklgkTAYct4R5Izmt4bqp64VD3fR1Y5BwckUzUQvTf/ZNu1Xl+Bv0CZfNksapadWdBa0w+b2VdXv0F14tKaGz9EqY+it68U1Lvw+h6IQzv3lWiEPCjM/UJKASDg949V3JDDTCq8EqB6xLmDQr3bJUwlcGrEr4xoAVwkXMuPWkSHgRsF9Fm0yxWPjCc44xhlx4Mdu1TzrGUCRcQ4xf5ULhawMWCieJWQwqTJge+oKAZcLLgr4AifA6yPoByxIuVNDsIQXCt55y/MAXXq1U94BtWgRbeOWV0rEEg/ITXuZ4R6VzhVcLOKJjmYzAFF4v4FvgCW9yvKOgmcJL34iCNioijvDGNwKbd9AZwjvfWwqal/DaKsDX6vzuXHg5Yt5FoetSWm6cemgbNLxk6NOEN/lGYDfKofA636CGZTbImXB2gza8Ij36Ho9dW4po0NF3WNYLKKRhLQcRjX5Q0ut6CurPpjk+l/TO172e7XvEo3BevnOMB13JXDwIb0L0a9B/ZnK/fdmE74W9fRPemthuOiXfU4QdZNelS/tKWe/2bgYL+EoPEcuEi/uKWQlX9xWfA9DCM85XdnCRn/OQh6Xt5mrkK4bY971REV/xPnyW9ByvUF9+Wqp9eC/ph40VyFe5C7wv8vTwfbFuZ6j34ON/77bok++58Bz6HWA0La9yPhR+vlo8gijp15jUPqQ+ETWyXW6ECNOxXT1EbCe729D7uYdne366qWI68OENK9fD0e4Dm/YHhfVu/PUz38Pv/CimMYbXiOvj8Ou/HYk53Ti8laVkf4vn9XtHgl45yz6J+9mTGfM8NIqHSbU9JFxBr3wBAAAAkMm/6Hn7P16i4woAAAAASUVORK5CYII=\n"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_detect(\"./test_images/synthetic characters/\", \"0-0-0-0-3.bmp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}